import argparse
import tempfile
import sys
import os
import shutil
import logging
import random
import time
import json
import socket
import subprocess
import platform
import base64
import requests
import psutil
import re
import stat
from datetime import datetime
from http.client import BadStatusLine, RemoteDisconnected
import urllib.parse
import html
from concurrent.futures import ThreadPoolExecutor, as_completed
from types import SimpleNamespace
from threading import Lock, Semaphore

from data.default_datas import *



# --- REALITY / FLOW éªŒè¯ ---
REALITY_PBK_RE = re.compile(r"^[A-Za-z0-9_-]{43,44}$")  # base64url publicKey
REALITY_SID_RE = re.compile(r"^[0-9a-fA-F]{0,32}$")  # shortId (hex, æœ€å¤š32å­—ç¬¦)

FLOW_ALIASES = {
    "xtls-rprx-visi": "xtls-rprx-vision",
}

FLOW_ALLOWED = {
    "",
    "xtls-rprx-vision",
}
# ------------------------------



# ------------ åŠ å¯† ------------
# Xray Shadowsocksï¼šå®˜æ–¹æ”¯æŒçš„åŠ å¯†æ–¹æ³•ï¼ˆæ›´æ–°äº2026-01-05ï¼‰
SS_ALLOWED_METHODS = {
    # Shadowsocks 2022
    "2022-blake3-aes-128-gcm",
    "2022-blake3-aes-256-gcm",
    "2022-blake3-chacha20-poly1305",

    # AEAD (æ—§ç‰ˆ)
    "aes-128-gcm",
    "aes-256-gcm",
    "chacha20-poly1305",
    "chacha20-ietf-poly1305",
    "xchacha20-poly1305",
    "xchacha20-ietf-poly1305",

    # æ— åŠ å¯†
    "none",
    "plain",
}
# ä¸æ”¯æŒçš„æ—§æ–¹æ³•ï¼ˆä»…ä¾›å‚è€ƒï¼‰ï¼š
# aes-128-cfb, aes-192-cfb, aes-256-cfb, aes-128-ctr, aes-256-ctr,
# camellia-128-cfb, camellia-256-cfb, rc4-md5, bf-cfb ç­‰
# ------------------------------



# ------------------------------
# ç¦ç”¨ InsecureRequestWarning æ¥å¿½ç•¥ SSL è¯ä¹¦éªŒè¯è­¦å‘Šã€‚
# å®ç°æŠ‘åˆ¶åŸºäºæ­¤åº“çš„requestsç­‰åº“çš„è­¦å‘Š
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
# ------------------------------



# ---------- èšåˆå™¨æ¨¡å— ----------
try:
    import aggregator

    AGGREGATOR_AVAILABLE = True
except ImportError:
    AGGREGATOR_AVAILABLE = False
# ------------------------------



# ------------ è®¾ç½® ------------
# é…ç½®æ–‡ä»¶
CONFIG_FILE = "./data/config.json"
SOURCES_FILE = "./data/sources.json"

# åŠ è½½sources.jsonï¼Œè‹¥ä¸å­˜åœ¨åˆ™åˆ›å»ºé»˜è®¤
def load_sources():
    """åŠ è½½sources.jsonï¼Œè‹¥ä¸å­˜åœ¨åˆ™åˆ›å»ºé»˜è®¤"""
    if os.path.exists(SOURCES_FILE):
        try:
            with open(SOURCES_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if isinstance(data, dict):
                    return data
        except Exception as e:
            print(f"åŠ è½½ {SOURCES_FILE} æ—¶å‡ºé”™ï¼š{e}")

    # æ²¡æœ‰ä»£ç†æºå°±åˆ›å»º,ä»£ç†æºç¤ºä¾‹
    try:
        with open(SOURCES_FILE, 'w', encoding='utf-8') as f:
            json.dump(DEFAULT_SOURCES_DATA, f, indent=4)
        print(f"å·²åˆ›å»ºé»˜è®¤ {SOURCES_FILE}")
    except Exception as e:
        print(f"åˆ›å»º {SOURCES_FILE} æ—¶å‡ºé”™ï¼š{e}")

    return DEFAULT_SOURCES_DATA

# åŠ è½½config.jsonï¼Œè‹¥ä¸å­˜åœ¨åˆ™åˆ›å»ºé»˜è®¤
def load_config():
    """åŠ è½½config.jsonï¼Œè‹¥ä¸å­˜åœ¨åˆ™åˆ›å»ºé»˜è®¤"""
    loaded_sources = load_sources()

    if not os.path.exists(CONFIG_FILE):
        try:
            config_to_write = DEFAULT_CONFIG.copy()
            del config_to_write["sources"]

            with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
                json.dump(config_to_write, f, indent=4)
            print(f"å·²åˆ›å»ºé»˜è®¤ {CONFIG_FILE}")
        except:
            pass
        cfg = DEFAULT_CONFIG.copy()
        cfg["sources"] = loaded_sources
        return cfg

    try:
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
            user_config = json.load(f)

        config = DEFAULT_CONFIG.copy()
        config.update(user_config)

        config["sources"] = loaded_sources

        has_new_keys = False
        keys_to_check = [k for k in DEFAULT_CONFIG.keys() if k != "sources"]

        for key in keys_to_check:
            if key not in user_config:
                has_new_keys = True
                break

        if has_new_keys:
            try:
                print(f">> æ›´æ–° {CONFIG_FILE}ï¼šæ·»åŠ æ–°å‚æ•°...")
                save_cfg = config.copy()
                if "sources" in save_cfg: del save_cfg["sources"]

                with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
                    json.dump(save_cfg, f, indent=4)
            except Exception as e:
                print(f"è­¦å‘Šï¼šæ— æ³•æ›´æ–°é…ç½®æ–‡ä»¶ï¼š{e}")

        return config
    except Exception as e:
        print(f"åŠ è½½é…ç½®æ–‡ä»¶æ—¶å‡ºé”™ï¼š{e}")
        cfg = DEFAULT_CONFIG.copy()
        cfg["sources"] = loaded_sources
        return cfg

# åŠ è½½è®¾ç½®
GLOBAL_CFG = load_config()
# ------------------------------



# ------------ å…¶ä»– -------------
# åè®®æç¤º
PROTO_HINTS = ("vless://", "vmess://", "trojan://", "hysteria2://", "hy2://", "ss://")

# BASE64å­—ç¬¦
BASE64_CHARS = set("ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=_-")

# æ­£åˆ™è¡¨è¾¾å¼å…¬ç”¨æå–æ¨¡æ¿
URL_FINDER = re.compile(
    r'(?:vless|vmess|trojan|hysteria2|hy2)://[^\s"\'<>]+|(?<![A-Za-z0-9+])ss://[^\s"\'<>]+',
    re.IGNORECASE
)
# ------------------------------



# ------- richç»ˆç«¯æ ·å¼å®šä¹‰ -------
# richåº“å‘ç»ˆç«¯å†™å…¥å¯Œæ–‡æœ¬ï¼ˆå¸¦é¢œè‰²å’Œæ ·å¼ï¼‰ï¼Œä»¥åŠæ˜¾ç¤ºé«˜çº§å†…å®¹
try:
    from rich.console import Console
    from rich.panel import Panel
    from rich.table import Table
    from rich.progress import Progress, SpinnerColumn, BarColumn, TextColumn, TimeElapsedColumn, TimeRemainingColumn
    from rich.prompt import Prompt, Confirm
    from rich.logging import RichHandler
    from rich import box
    from rich.text import Text

    console = Console()
except ImportError:
    print("è¯·å®‰è£…richåº“ï¼špip install rich")
    sys.exit(1)

class Fore:
    """å‰æ™¯è‰²æ ·å¼æ ‡ç­¾"""
    CYAN = "[cyan]"
    GREEN = "[green]"
    RED = "[red]"
    YELLOW = "[yellow]"
    MAGENTA = "[magenta]"
    BLUE = "[blue]"
    WHITE = "[white]"
    LIGHTBLACK_EX = "[dim]"
    LIGHTGREEN_EX = "[bold green]"
    LIGHTRED_EX = "[bold red]"
    RESET = "[/]"

class Style:
    BRIGHT = "[bold]"
    RESET_ALL = "[/]"
# ------------------------------



# è§„èŒƒåŒ–URLï¼šç§»é™¤BOMã€ä¸å¯è§å­—ç¬¦
def clean_url(url):
    """
    è§„èŒƒåŒ–URLï¼šç§»é™¤BOMã€ä¸å¯è§å­—ç¬¦ï¼Œ
    è§£ç HTMLå®ä½“ï¼ˆ&amp; â†’ &ï¼‰å’ŒURLç¼–ç ï¼ˆ%26 â†’ &ï¼‰ã€‚
    è¿›è¡Œä¸¤æ¬¡è§£ç ä»¥å¤„ç†åµŒå¥—è½¬ä¹‰ï¼ˆå¦‚ &amp%3B æˆ– %26amp%3Bï¼‰ã€‚
    """
    url = url.strip()
    url = url.replace('\ufeff', '').replace('\u200b', '')
    url = url.replace('\n', '').replace('\r', '')

    url = html.unescape(url)
    url = urllib.parse.unquote(url)

    url = html.unescape(url)
    url = urllib.parse.unquote(url)

    return url


# å•å…ƒæµ‹è¯•,æ£€æŸ¥VLESS/REALITYå‚æ•°è§£ç æ˜¯å¦æ­£ç¡®ã€‚
def _self_test_clean_url():
    """
    clean_url()çš„å•å…ƒæµ‹è¯•ï¼šæ£€æŸ¥VLESS/REALITYå‚æ•°è§£ç æ˜¯å¦æ­£ç¡®ã€‚
    è¿è¡Œæ–¹å¼ï¼špython v2rayChecker.py --self-test

    Returns:
        bool: æ‰€æœ‰æµ‹è¯•é€šè¿‡è¿”å›True
    """
    test_cases = [
        # (è¾“å…¥å­—ç¬¦ä¸², æ¸…ç†åé¢„æœŸåŒ…å«çš„å­ä¸²)
        ("vless://test@host:443?security=reality&amp;pbk=ABC&amp;sid=123", "security=reality&pbk=ABC&sid=123"),
        ("vless://test@host:443?security=reality&amp%3Bpbk=ABC", "security=reality&pbk=ABC"),
        ("vless://test@host:443?security=reality%26amp%3Bpbk=ABC", "security=reality&pbk=ABC"),
        ("vless://test@host:443?flow=xtls-rprx-vision&type=tcp", "flow=xtls-rprx-vision&type=tcp"),
    ]

    passed = 0
    for raw, expected in test_cases:
        cleaned = clean_url(raw)
        if "?" in cleaned:
            query = cleaned.split("?", 1)[1]
            params = urllib.parse.parse_qs(query)
            has_separate_keys = "security" in params or "pbk" in params or "flow" in params
            if has_separate_keys or expected in cleaned:
                passed += 1
                safe_print(f"[green]âœ“ é€šè¿‡[/]ï¼š{raw[:60]}...")
            else:
                safe_print(f"[red]âœ— å¤±è´¥[/]ï¼š{raw[:60]}...")
                safe_print(f"[dim]  å¾—åˆ°ï¼š{cleaned[:100]}[/]")
        else:
            passed += 1

    safe_print(f"\n[bold]è‡ªæµ‹ï¼š{passed}/{len(test_cases)} é€šè¿‡[/]")
    return passed == len(test_cases)


# æ™ºèƒ½æ—¥å¿—å™¨ï¼ŒåŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶
class SmartLogger:
    """æ™ºèƒ½æ—¥å¿—å™¨ï¼ŒåŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶"""

    def __init__(self, filename="./data/checker_history.log"):
        self.filename = filename
        self.lock = Lock()
        try:
            with open(self.filename, 'a', encoding='utf-8') as f:
                f.write(
                    f"\n{'-' * 30} æ–°ä¼šè¯ "
                    f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} {'-' * 30}\n"
                )
        except Exception as e:
            console.print(f"[bold red]åˆ›å»ºæ—¥å¿—æ–‡ä»¶å¤±è´¥ï¼š{e}[/]")

    def log(self, msg, style=None):
        with self.lock:
            console.print(msg, style=style, highlight=False)

            try:
                text_obj = Text.from_markup(str(msg))
                clean_msg = text_obj.plain.strip()

                if clean_msg:
                    timestamp = datetime.now().strftime("[%H:%M:%S]")
                    log_line = f"{timestamp} {clean_msg}\n"

                    with open(self.filename, 'a', encoding='utf-8') as f:
                        f.write(log_line)
            except Exception:
                pass

MAIN_LOGGER = SmartLogger("./data/checker_history.log")
logging.basicConfig(format="%(asctime)s - %(message)s", level=logging.INFO, datefmt='%H:%M:%S')

# å®‰å…¨æ‰“å°åˆ°æ§åˆ¶å°å¹¶å†™å…¥æ—¥å¿—
def safe_print(msg):
    """å®‰å…¨æ‰“å°åˆ°æ§åˆ¶å°å¹¶å†™å…¥æ—¥å¿—"""
    MAIN_LOGGER.log(msg)


TEMP_DIR = tempfile.mkdtemp()
OS_SYSTEM = platform.system().lower()
CORE_PATH = ""
CTRL_C = False


# ------------------------------ æ ¸å¿ƒåŠŸèƒ½ ------------------------------
# æ£€æŸ¥æœ¬åœ°ç«¯å£æ˜¯å¦å·²è¢«å ç”¨
def is_port_in_use(port):
    """æ£€æŸ¥æœ¬åœ°ç«¯å£æ˜¯å¦å·²è¢«å ç”¨"""
    try:
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.settimeout(0.1)
            return s.connect_ex(('127.0.0.1', port)) == 0
    except:
        return False

# æœªç”¨ - ç­‰å¾…æ ¸å¿ƒå¯åŠ¨ï¼ˆç«¯å£ç›‘å¬ï¼‰
def wait_for_core_start(port, max_wait):
    """ç­‰å¾…æ ¸å¿ƒå¯åŠ¨ï¼ˆç«¯å£ç›‘å¬ï¼‰"""
    start_time = time.time()
    while time.time() - start_time < max_wait:
        if is_port_in_use(port):
            return True
        time.sleep(0.05)
    return False

# å°†åˆ—è¡¨åˆ†å‰²æˆnä¸ªå­åˆ—è¡¨
def split_list(lst, n):
    """å°†åˆ—è¡¨åˆ†å‰²æˆnä¸ªå­åˆ—è¡¨"""
    if n <= 0: return []
    k, m = divmod(len(lst), n)
    return (lst[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))

# å°è¯•è§£ç å¯èƒ½ä¸ºbase64çš„æ–‡æœ¬ï¼Œæå–å…¶ä¸­çš„ä»£ç†é“¾æ¥
def try_decode_base64(text):
    """å°è¯•è§£ç å¯èƒ½ä¸ºbase64çš„æ–‡æœ¬ï¼Œæå–å…¶ä¸­çš„ä»£ç†é“¾æ¥"""
    raw = text.strip()
    if not raw:
        return raw

    if any(marker in raw for marker in PROTO_HINTS):
        return raw

    compact = re.sub(r'\s+', '', raw)
    if not compact or not set(compact) <= BASE64_CHARS:
        return raw

    missing_padding = len(compact) % 4
    if missing_padding:
        compact += "=" * (4 - missing_padding)

    for decoder in (base64.b64decode, base64.urlsafe_b64decode):
        try:
            decoded = decoder(compact).decode("utf-8", errors="ignore")
        except Exception:
            continue
        if any(marker in decoded for marker in PROTO_HINTS):
            return decoded
    return raw

# ç”Ÿæˆç»™å®šæ–‡æœ¬çš„å¯èƒ½å˜ä½“ï¼ˆåŸå§‹/è§£ç åï¼‰
def _payload_variants(blob):
    """ç”Ÿæˆç»™å®šæ–‡æœ¬çš„å¯èƒ½å˜ä½“ï¼ˆåŸå§‹/è§£ç åï¼‰"""
    clean_blob = blob.strip()
    if not clean_blob:
        return set()

    variants = {clean_blob}

    decoded_blob = try_decode_base64(clean_blob)

    if decoded_blob and decoded_blob != clean_blob:
        variants.add(decoded_blob)
    for line in clean_blob.splitlines():
        line = line.strip()
        if not line:
            continue
        maybe_decoded = try_decode_base64(line)
        if maybe_decoded and maybe_decoded != line:
            variants.add(maybe_decoded)

    return variants

# ä»æ–‡æœ¬ä¸­æå–æ‰€æœ‰ä»£ç†é“¾æ¥
def parse_content(text):
    """ä»æ–‡æœ¬ä¸­æå–æ‰€æœ‰ä»£ç†é“¾æ¥"""
    unique_links = set()
    raw_hits = 0

    for payload in _payload_variants(text):
        matches = URL_FINDER.findall(payload)
        raw_hits += len(matches)
        for item in matches:
            cleaned = clean_url(item.rstrip(';,)]}'))
            if cleaned and len(cleaned) > 15:
                unique_links.add(cleaned)

    return list(unique_links), raw_hits or len(unique_links)

# ä¸‹è½½URLå†…å®¹å¹¶æå–ä»£ç†é“¾æ¥
def fetch_url(url):
    """ä¸‹è½½URLå†…å®¹å¹¶æå–ä»£ç†é“¾æ¥"""
    try:
        safe_print(f"{Fore.CYAN}>> æ­£åœ¨ä¸‹è½½URLï¼š{url}{Style.RESET_ALL}")
        resp = requests.get(url, timeout=15, verify=False)
        if resp.status_code == 200:
            links, count = parse_content(resp.text)
            return links
        else:
            safe_print(f"{Fore.RED}>> ä¸‹è½½å¤±è´¥ï¼šHTTP {resp.status_code}{Style.RESET_ALL}")
    except Exception as e:
        safe_print(f"{Fore.RED}>> URLé”™è¯¯ï¼š{e}{Style.RESET_ALL}")
    return []

# è§£æVLESSé“¾æ¥
def parse_vless(url):
    """è§£æVLESSé“¾æ¥"""
    try:
        url = clean_url(url)
        if not url.startswith("vless://"): return None

        main_part = url
        tag = "vless"
        if '#' in url:
            parts = url.split('#', 1)
            main_part = parts[0]
            tag = urllib.parse.unquote(parts[1]).strip()

        if 'Â¬' in main_part: main_part = main_part.split('Â¬')[0]

        match = re.search(r'vless://([^@]+)@([^:]+):(\d+)', main_part)
        if not match: return None

        uuid = match.group(1).strip()
        address = match.group(2).strip()
        port = int(match.group(3))

        params = {}
        if '?' in main_part:
            query = main_part.split('?', 1)[1]
            query = re.split(r'[^\w\-\=\&\%(\.)]', query)[0]
            params = urllib.parse.parse_qs(query)

        def get_p(key, default=""):
            val = params.get(key, [default])
            v = val[0].strip()
            return re.sub(r'[^\x20-\x7E]', '', v) if v else default

        net_type = get_p("type", "tcp").lower()
        net_type = re.sub(r"[^a-z0-9]", "", net_type)
        if net_type in ["http", "h2"]:
            net_type = "xhttp"
        elif net_type == "httpupgrade":
            net_type = "xhttp"

        flow = get_p("flow", "").lower().strip()
        flow = FLOW_ALIASES.get(flow, flow)

        if flow in ["none", "xtls-rprx-direct", "xtls-rprx-origin",
                    "xtls-rprx-splice", "xtls-rprx-direct-udp443"]:
            flow = ""

        if flow not in FLOW_ALLOWED:
            flow = ""

        security = get_p("security", "none").lower()
        if security not in ["tls", "reality", "none", "auto"]:
            security = "none"

        if flow and security not in ["tls", "reality"]:
            if GLOBAL_CFG.get("debug_mode"):
                safe_print(f"[yellow][è°ƒè¯•] ä¸¢å¼ƒ flow={flow}ï¼Œsecurity={security}ï¼ˆflowéœ€è¦tls/realityï¼‰[/]")
            flow = ""

        pbk = get_p("pbk", "")
        # éªŒè¯ï¼šä¸¥æ ¼æ£€æŸ¥X25519å…¬é’¥ï¼ˆbase64url â†’ 32å­—èŠ‚ï¼‰
        if pbk:
            try:
                missing_padding = len(pbk) % 4
                pbk_padded = pbk + '=' * (4 - missing_padding) if missing_padding else pbk

                decoded = base64.urlsafe_b64decode(pbk_padded)

                if len(decoded) != 32:
                    if GLOBAL_CFG.get("debug_mode"):
                        safe_print(f"[yellow][è°ƒè¯•] ä¸¢å¼ƒæ— æ•ˆPBKï¼ˆé•¿åº¦{len(decoded)}!=32ï¼‰ï¼š{pbk}[/]")
                    pbk = ""
            except Exception as e:
                if GLOBAL_CFG.get("debug_mode"):
                    safe_print(f"[yellow][è°ƒè¯•] ä¸¢å¼ƒæ— æ•ˆPBKï¼ˆè§£ç é”™è¯¯ï¼‰ï¼š{pbk} ({e})[/]")
                pbk = ""

        if pbk and security == "tls":
            security = "reality"

        sid = get_p("sid", "")
        # éªŒè¯ShortIdï¼šå¿…é¡»æ˜¯hexä¸”å¶æ•°é•¿åº¦
        if sid:
            sid = re.sub(r"[^0-9a-fA-F]", "", sid)
            if len(sid) % 2 != 0:
                if GLOBAL_CFG.get("debug_mode"):
                    safe_print(f"[yellow][è°ƒè¯•] ä¿®æ­£å¥‡æ•°SIDé•¿åº¦ {len(sid)}ï¼š{sid} -> 0{sid}[/]")
                sid = "0" + sid

            if not REALITY_SID_RE.match(sid):
                sid = ""

        return {
            "protocol": "vless",
            "uuid": uuid,
            "address": address,
            "port": port,
            "encryption": get_p("encryption", "none"),
            "type": net_type,
            "security": security,
            "path": urllib.parse.unquote(get_p("path", "")),
            "host": get_p("host", ""),
            "sni": get_p("sni", ""),
            "fp": get_p("fp", ""),
            "alpn": get_p("alpn", ""),
            "serviceName": get_p("serviceName", ""),
            "mode": get_p("mode", ""),
            "pbk": pbk,
            "sid": sid,
            "flow": flow,
            "headerType": get_p("headerType", ""),
            "tag": tag
        }
    except Exception as e:
        return None

# è§£æVMessé“¾æ¥
def parse_vmess(url):
    """è§£æVMessé“¾æ¥"""
    try:
        url = clean_url(url)
        if not url.startswith("vmess://"): return None

        if '@' in url:
            if '#' in url:
                main_part, tag = url.split('#', 1)
                tag = urllib.parse.unquote(tag).strip()
            else:
                main_part = url
                tag = "vmess"

            match = re.search(r'vmess://([^@]+)@([^:]+):(\d+)', main_part)
            if match:
                uuid = match.group(1).strip()
                address = match.group(2).strip()
                port = int(match.group(3))

                params = {}
                if '?' in main_part:
                    query = main_part.split('?', 1)[1]
                    params = urllib.parse.parse_qs(query)

                def get_p(key, default=""):
                    val = params.get(key, [default])
                    return val[0] if val else default

                try:
                    aid = int(get_p("aid", "0"))
                except:
                    aid = 0

                raw_path = get_p("path", "")
                final_path = urllib.parse.unquote(raw_path)

                net_type = get_p("type", "tcp").lower()
                if net_type in ["http", "h2", "httpupgrade"]:
                    net_type = "xhttp"

                return {
                    "protocol": "vmess",
                    "uuid": uuid,
                    "address": address,
                    "port": int(port),
                    "type": net_type,
                    "security": get_p("security", "none"),
                    "path": final_path,
                    "host": get_p("host", ""),
                    "sni": get_p("sni", ""),
                    "fp": get_p("fp", ""),
                    "alpn": get_p("alpn", ""),
                    "serviceName": get_p("serviceName", ""),
                    "aid": aid,
                    "scy": get_p("encryption", "auto"),
                    "tag": tag
                }

        content = url[8:]
        if '#' in content:
            b64, tag = content.rsplit('#', 1)
            tag = urllib.parse.unquote(tag).strip()
        else:
            b64 = content
            tag = "vmess"

        missing_padding = len(b64) % 4
        if missing_padding: b64 += '=' * (4 - missing_padding)

        try:
            decoded = base64.b64decode(b64).decode('utf-8', errors='ignore')
            data = json.loads(decoded)

            net_type = data.get("net", "tcp")
            if net_type in ["http", "h2", "httpupgrade"]:
                net_type = "xhttp"

            return {
                "protocol": "vmess",
                "uuid": data.get("id"),
                "address": data.get("add"),
                "port": int(data.get("port", 0)),
                "aid": int(data.get("aid", 0)),
                "type": net_type,
                "security": data.get("tls", "") if data.get("tls") else "none",
                "path": data.get("path", ""),
                "host": data.get("host", ""),
                "sni": data.get("sni", ""),
                "fp": data.get("fp", ""),
                "alpn": data.get("alpn", ""),
                "scy": data.get("scy", "auto"),
                "tag": data.get("ps", tag)
            }
        except:
            pass

        return None
    except Exception as e:
        safe_print(f"{Fore.RED}[VMESSé”™è¯¯] {e}{Style.RESET_ALL}")
        return None

# è§£æTrojané“¾æ¥
def parse_trojan(url):
    """è§£æTrojané“¾æ¥"""
    try:
        if '#' in url:
            url_clean, tag = url.split('#', 1)
        else:
            url_clean = url
            tag = "trojan"

        parsed = urllib.parse.urlparse(url_clean)
        params = urllib.parse.parse_qs(parsed.query)

        if not parsed.hostname or not parsed.port:
            return None

        return {
            "protocol": "trojan",
            "uuid": parsed.username,
            "address": parsed.hostname,
            "port": int(parsed.port),
            "security": params.get("security", ["tls"])[0],
            "sni": params.get("sni", [""])[0] or params.get("peer", [""])[0],
            "type": params.get("type", ["tcp"])[0],
            "path": params.get("path", [""])[0],
            "host": params.get("host", [""])[0],
            "tag": urllib.parse.unquote(tag).strip()
        }
    except:
        return None

# è§£æShadowsocksé“¾æ¥
def parse_ss(url):
    """è§£æShadowsocksé“¾æ¥"""
    try:
        if '#' in url:
            url_clean, tag = url.split('#', 1)
        else:
            url_clean = url
            tag = "ss"

        parsed = urllib.parse.urlparse(url_clean)

        if '@' in url_clean:
            userinfo = parsed.username
            try:
                if userinfo and ':' not in userinfo:
                    missing_padding = len(userinfo) % 4
                    if missing_padding: userinfo += '=' * (4 - missing_padding)
                    decoded_info = base64.b64decode(userinfo).decode('utf-8')
                else:
                    decoded_info = userinfo
            except:
                decoded_info = userinfo

            if not decoded_info or ':' not in decoded_info: return None
            method, password = decoded_info.split(':', 1)
            address = parsed.hostname
            port = parsed.port
        else:
            b64 = url_clean.replace("ss://", "")
            missing_padding = len(b64) % 4
            if missing_padding: b64 += '=' * (4 - missing_padding)
            decoded = base64.b64decode(b64).decode('utf-8')
            if '@' not in decoded: return None
            method_pass, addr_port = decoded.rsplit('@', 1)
            method, password = method_pass.split(':', 1)
            address, port = addr_port.rsplit(':', 1)

        if not address or not port: return None

        method_lower = method.lower().strip()

        # åˆ«åå¤„ç†
        if method_lower == "chacha20-poly1305":
            method_lower = "chacha20-ietf-poly1305"
        elif method_lower == "xchacha20-poly1305":
            method_lower = "xchacha20-ietf-poly1305"

        # éªŒè¯ï¼šä»…æ”¯æŒXrayå…è®¸çš„åŠ å¯†æ–¹å¼
        # CFB/CTR/OFBæµå¯†ç ä¼šå¯¼è‡´Exit 23ï¼
        if method_lower not in SS_ALLOWED_METHODS:
            if GLOBAL_CFG.get("debug_mode"):
                safe_print(f"[yellow][è°ƒè¯•] ä¸¢å¼ƒSSé“¾æ¥ï¼šä¸æ”¯æŒçš„åŠ å¯†æ–¹æ³• '{method}'ï¼ˆä»…å…è®¸AEADï¼‰[/]")
            return None

        return {
            "protocol": "shadowsocks",
            "address": address,
            "port": int(port),
            "method": method_lower,
            "password": password,
            "tag": urllib.parse.unquote(tag).strip()
        }
    except:
        return None

# è§£æHysteria2é“¾æ¥
def parse_hysteria2(url):
    """è§£æHysteria2é“¾æ¥"""
    try:
        url = url.replace("hy2://", "hysteria2://")
        if '#' in url:
            url_clean, tag = url.split('#', 1)
        else:
            url_clean = url
            tag = "hy2"

        parsed = urllib.parse.urlparse(url_clean)
        params = urllib.parse.parse_qs(parsed.query)

        if not parsed.hostname or not parsed.port:
            return None

        return {
            "protocol": "hysteria2",
            "uuid": parsed.username,
            "address": parsed.hostname,
            "port": int(parsed.port),
            "sni": params.get("sni", [""])[0],
            "insecure": params.get("insecure", ["0"])[0] == "1",
            "obfs": params.get("obfs", ["none"])[0],
            "obfs_password": params.get("obfs-password", [""])[0],
            "tag": urllib.parse.unquote(tag).strip()
        }
    except:
        return None

# ä»é“¾æ¥ä¸­æå–æ ‡ç­¾ï¼ˆå¤‡æ³¨ï¼‰
def get_proxy_tag(url):
    """ä»é“¾æ¥ä¸­æå–æ ‡ç­¾ï¼ˆå¤‡æ³¨ï¼‰"""
    tag = "proxy"
    try:
        url = clean_url(url)
        if '#' in url:
            _, raw_tag = url.rsplit('#', 1)
            tag = urllib.parse.unquote(raw_tag).strip()
        elif url.startswith("vmess"):
            res = parse_vmess(url)
            if res: tag = res.get('tag', 'vmess')
    except:
        pass

    tag = re.sub(r'[^\w\-\.]', '_', tag)
    return tag if tag else "proxy"

# éªŒè¯UUIDæ ¼å¼
def is_valid_uuid(uuid_str):
    """éªŒè¯UUIDæ ¼å¼"""
    if not uuid_str: return False
    pattern = re.compile(r'^[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}$')
    return bool(pattern.match(str(uuid_str)))

# éªŒè¯ç«¯å£å·
def is_valid_port(port):
    """éªŒè¯ç«¯å£å·"""
    try:
        p = int(port)
        return 1 <= p <= 65535
    except:
        return False

# ç”ŸæˆXrayå‡ºç«™é…ç½®ç»“æ„
def get_outbound_structure(proxy_url, tag):
    """ç”ŸæˆXrayå‡ºç«™é…ç½®ç»“æ„"""
    safe_print(f"[outbound] â–¶ï¸ å¼€å§‹å¤„ç†: {proxy_url[:80]}...")  if GLOBAL_CFG.get("debug_mode") else 0

    try:
        proxy_url = clean_url(proxy_url)
        proxy_conf = None

        if proxy_url.startswith("vless://"):
            proxy_conf = parse_vless(proxy_url)
        elif proxy_url.startswith("vmess://"):
            proxy_conf = parse_vmess(proxy_url)
        elif proxy_url.startswith("trojan://"):
            proxy_conf = parse_trojan(proxy_url)
        elif proxy_url.startswith("ss://"):
            proxy_conf = parse_ss(proxy_url)
        elif proxy_url.startswith("hy"):
            proxy_conf = parse_hysteria2(proxy_url)

        # if not proxy_conf or not proxy_conf.get("address"): return None
        # if not is_valid_port(proxy_conf.get("port")): return None
        #
        # if proxy_conf["protocol"] in ["vless", "vmess"]:
        #     if not is_valid_uuid(proxy_conf.get("uuid")): return None
        # ä¸Šæ–¹ä»£ç æ”¹æˆè°ƒè¯•ç‰ˆ
        if not proxy_conf:
            safe_print(f"[outbound] âŒ proxy_conf ä¸ºç©ºï¼Œè§£æå¤±è´¥") if GLOBAL_CFG.get("debug_mode") else 0
            return None
        if not proxy_conf.get("address"):
            safe_print(f"[outbound] âŒ æ— addressï¼Œconf={proxy_conf}") if GLOBAL_CFG.get("debug_mode") else 0
            return None
        if not is_valid_port(proxy_conf.get("port")):
            safe_print(f"[outbound] âŒ ç«¯å£æ— æ•ˆ: {proxy_conf.get('port')}") if GLOBAL_CFG.get("debug_mode") else 0
            return None

        if proxy_conf["protocol"] in ["vless", "vmess"]:
            if not is_valid_uuid(proxy_conf.get("uuid")):
                safe_print(f"[outbound] âŒ UUIDæ— æ•ˆ: {proxy_conf.get('uuid')}") if GLOBAL_CFG.get("debug_mode") else 0
                return None

        net_type = proxy_conf.get("type", "tcp").lower()
        header_type = proxy_conf.get("headerType", "").lower()

        if net_type == "http" or header_type == "http":
            return None

        streamSettings = {}
        security = proxy_conf.get("security", "none").lower()

        original_net_type = net_type
        if net_type in ["ws", "websocket"]:
            net_type = "xhttp"
        elif net_type in ["grpc", "gun"]:
            net_type = "xhttp"
        elif net_type in ["http", "h2"]:
            net_type = "xhttp"
        elif net_type == "httpupgrade":
            net_type = "xhttp"
        elif net_type not in ["tcp", "kcp", "quic", "xhttp"]:
            net_type = "tcp"

        if proxy_conf["protocol"] in ["vless", "vmess", "trojan"]:
            if security == "auto":
                security = "none"

            streamSettings = {
                "network": net_type,
                "security": security
            }

            alpn_val = None
            raw_alpn = proxy_conf.get("alpn")
            if raw_alpn:
                if isinstance(raw_alpn, list):
                    alpn_val = raw_alpn
                elif isinstance(raw_alpn, str):
                    alpn_val = raw_alpn.split(",")

            tls_settings = {
                "serverName": proxy_conf.get("sni") or proxy_conf.get("host") or "",
                "allowInsecure": True,
                "fingerprint": proxy_conf.get("fp", "chrome")
            }

            if alpn_val:
                tls_settings["alpn"] = alpn_val

            if security == "tls":
                streamSettings["tlsSettings"] = tls_settings
            elif security == "reality":
                if not proxy_conf.get("pbk"):
                    return None
                s_id = proxy_conf.get("sid", "")
                if len(s_id) % 2 != 0:
                    s_id = ""
                streamSettings["realitySettings"] = {
                    "publicKey": proxy_conf.get("pbk"),
                    "shortId": s_id,
                    "serverName": tls_settings["serverName"],
                    "fingerprint": tls_settings["fingerprint"],
                    "spiderX": "/"
                }

            path = proxy_conf.get("path") or "/"
            host = proxy_conf.get("host") or ""

            if net_type == "xhttp":
                mode = "auto"
                if original_net_type in ["grpc", "gun"]:
                    mode = "stream-up"
                    if not path or path == "/":
                        path = proxy_conf.get("serviceName") or "/"

                streamSettings["xhttpSettings"] = {
                    "path": path,
                    "host": host,
                    "mode": mode
                }
            elif net_type == "tcp":
                if proxy_conf.get("headerType") and proxy_conf.get("headerType").lower() != "none":
                    return None
            elif net_type == "kcp":
                streamSettings["kcpSettings"] = {
                    "header": {"type": proxy_conf.get("headerType") or "none"}
                }
            elif net_type == "quic":
                streamSettings["quicSettings"] = {
                    "security": proxy_conf.get("quicSecurity") or "none",
                    "key": proxy_conf.get("key") or "",
                    "header": {"type": proxy_conf.get("headerType") or "none"}
                }

        outbound = {
            "protocol": proxy_conf["protocol"],
            "tag": tag,
            "streamSettings": streamSettings
        }

        if proxy_conf["protocol"] == "shadowsocks":
            method = proxy_conf["method"].lower()
            if "chacha20-ietf" in method and "poly1305" not in method:
                method = "chacha20-ietf-poly1305"
            outbound["settings"] = {
                "servers": [{
                    "address": proxy_conf["address"],
                    "port": int(proxy_conf["port"]),
                    "method": method,
                    "password": proxy_conf["password"]
                }]
            }
            outbound.pop("streamSettings", None)

        elif proxy_conf["protocol"] == "trojan":
            outbound["settings"] = {
                "servers": [{
                    "address": proxy_conf["address"],
                    "port": int(proxy_conf["port"]),
                    "password": proxy_conf["uuid"]
                }]
            }

        elif proxy_conf["protocol"] == "hysteria2":
            hy2_settings = {
                "address": proxy_conf["address"],
                "port": int(proxy_conf["port"]),
                "users": [{"password": proxy_conf["uuid"]}]
            }
            if proxy_conf.get("obfs") and proxy_conf.get("obfs") != "none":
                hy2_settings["obfs"] = {
                    "type": proxy_conf["obfs"],
                    "password": proxy_conf.get("obfs_password", "")
                }
            outbound["settings"] = {"vnext": [hy2_settings]}
            outbound["streamSettings"] = {
                "security": "tls",
                "tlsSettings": {
                    "serverName": proxy_conf.get("sni", ""),
                    "allowInsecure": True,
                    "fingerprint": "chrome"
                }
            }
            if alpn_val:
                outbound["streamSettings"]["tlsSettings"]["alpn"] = alpn_val
        else:
            vnext_user = {
                "id": proxy_conf["uuid"],
                "alterId": proxy_conf.get("aid", 0),
                "encryption": "none"
            }
            if proxy_conf["protocol"] == "vless" and proxy_conf.get("flow"):
                vnext_user["flow"] = proxy_conf.get("flow")

            outbound["settings"] = {
                "vnext": [{
                    "address": proxy_conf["address"],
                    "port": int(proxy_conf["port"]),
                    "users": [vnext_user]
                }]
            }
        safe_print(f"[outbound] âœ… æˆåŠŸæ„å»º outboundï¼Œtag={tag}") if GLOBAL_CFG.get("debug_mode") else 0
        return outbound

    except Exception as e:
        safe_print(f"[outbound] âŒ å¼‚å¸¸: {e}")  if GLOBAL_CFG.get("debug_mode") else 0
        return None

# ä¸ºä¸€æ‰¹ä»£ç†åˆ›å»ºXrayé…ç½®æ–‡ä»¶
def create_batch_config_file(proxy_list, start_port, work_dir):
    """ä¸ºä¸€æ‰¹ä»£ç†åˆ›å»ºXrayé…ç½®æ–‡ä»¶"""
    inbounds = []
    outbounds = []
    rules = []
    valid_proxies = []

    for i, url in enumerate(proxy_list):
        port = start_port + i
        in_tag = f"in_{port}"
        out_tag = f"out_{port}"

        out_struct = get_outbound_structure(url, out_tag)
        if not out_struct:
            continue

        if "streamSettings" in out_struct:
            ss = out_struct["streamSettings"]
            net = ss.get("network", "")

            if net == "xhttp":
                ss.pop("wsSettings", None)
                ss.pop("grpcSettings", None)
                ss.pop("httpSettings", None)
                ss.pop("h2Settings", None)
                ss.pop("httpupgradeSettings", None)

        inbounds.append({
            "port": port,
            "listen": "127.0.0.1",
            "protocol": "socks",
            "tag": in_tag,
            "settings": {"udp": False}
        })

        outbounds.append(out_struct)
        rules.append({
            "type": "field",
            "inboundTag": [in_tag],
            "outboundTag": out_tag
        })
        valid_proxies.append((url, port))

    if not outbounds:
        return None, None, "æ— æœ‰æ•ˆä»£ç†"

    full_config = {
        "log": {"loglevel": "warning"},  # warningä¾¿äºè¯Šæ–­ï¼Œnoneä¼šéšè—é”™è¯¯
        "inbounds": inbounds,
        "outbounds": outbounds,
        "routing": {
            "domainStrategy": "AsIs",
            "rules": rules
        }
    }

    config_path = os.path.join(work_dir, f"batch_{start_port}.json")
    with open(config_path, 'w') as f:
        json.dump(full_config, f, indent=2)

    return config_path, valid_proxies, None

# ä¿å­˜å¤±è´¥çš„æ‰¹å¤„ç†é…ç½®å’Œé”™è¯¯æ—¥å¿—
def save_failed_batch(config_path, error_output, exit_code):
    """ä¿å­˜å¤±è´¥çš„æ‰¹å¤„ç†é…ç½®å’Œé”™è¯¯æ—¥å¿—"""
    try:
        failed_dir = os.path.join(os.getcwd(), "failed_batches")
        os.makedirs(failed_dir, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        base_name = os.path.basename(config_path).replace(".json", "")

        dest_json = os.path.join(failed_dir, f"{base_name}_{timestamp}.json")
        shutil.copy2(config_path, dest_json)

        log_path = os.path.join(failed_dir, f"{base_name}_{timestamp}.log.txt")
        with open(log_path, 'w', encoding='utf-8') as f:
            f.write(f"é€€å‡ºä»£ç ï¼š{exit_code}\n")
            f.write(f"æ—¶é—´æˆ³ï¼š{timestamp}\n")
            f.write(f"é…ç½®æ–‡ä»¶ï¼š{config_path}\n")
            f.write("-" * 50 + "\n")
            f.write(error_output or "æœªæ•è·è¾“å‡º")

        safe_print(f"[yellow]ğŸ“ è°ƒè¯•æ–‡ä»¶å·²ä¿å­˜è‡³ï¼š{failed_dir}[/]")
        safe_print(f"[dim]   é‡ç°å‘½ä»¤ï¼šxray run -test -c \"{dest_json}\"[/]")

        return dest_json, log_path
    except Exception as e:
        safe_print(f"[red]ä¿å­˜è°ƒè¯•å·¥ä»¶å¤±è´¥ï¼š{e}[/]")
        return None, None

# å¯åŠ¨Xrayæ ¸å¿ƒ
def run_core(core_path, config_path):
    """å¯åŠ¨Xrayæ ¸å¿ƒ"""
    if platform.system() != "Windows":
        try:
            st = os.stat(core_path)
            os.chmod(core_path, st.st_mode | stat.S_IXEXEC)
        except Exception as e:
            pass
    cmd = [core_path, "run", "-c", config_path] if "xray" in core_path.lower() else [core_path, "-c", config_path]
    startupinfo = None
    if OS_SYSTEM == "windows":
        startupinfo = subprocess.STARTUPINFO()
        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
    try:
        return subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            startupinfo=startupinfo,
            text=True,
            bufsize=1,
            universal_newlines=True
        )
    except Exception as e:
        safe_print(f"[bold red]æ ¸å¿ƒå¯åŠ¨é”™è¯¯ï¼š{e}[/]")
        return None

# æ€æ­»æ ¸å¿ƒè¿›ç¨‹åŠå…¶å­è¿›ç¨‹
def kill_core(proc):
    """æ€æ­»æ ¸å¿ƒè¿›ç¨‹åŠå…¶å­è¿›ç¨‹"""
    if not proc:
        return

    try:
        if psutil.pid_exists(proc.pid):
            parent = psutil.Process(proc.pid)
            # æ€æ­»å­è¿›ç¨‹
            for child in parent.children(recursive=True):
                try:
                    child.kill()
                except:
                    pass
            parent.kill()
        else:
            if OS_SYSTEM == "windows":
                subprocess.run(["taskkill", "/F", "/PID", str(proc.pid)],
                               capture_output=True)
    except:
        pass

    try:
        proc.terminate()
        proc.wait(timeout=1.0)
    except:
        try:
            proc.kill()
        except:
            pass

# é€šè¿‡SOCKS5ä»£ç†æµ‹è¯•è¿é€šæ€§
def check_connection(local_port, domain, timeout):
    """é€šè¿‡SOCKS5ä»£ç†æµ‹è¯•è¿é€šæ€§ï¼Œå¹¶è®°å½•å¤±è´¥åŸå› """

    # ä¸è¦å¿˜äº†å®‰è£…requestsçš„socksæ”¯æŒ,ä¸Šæ¬¡è°ƒè¯•äº†æ•´æ•´2å¤©æ‰æ‰¾åˆ°é—®é¢˜
    try:
        import socks  # ä»…ç”¨äºæ£€æµ‹ä¾èµ–æ˜¯å¦å­˜åœ¨
    except ImportError:
        safe_print("[bold red]é”™è¯¯ï¼šæœªå®‰è£… PySocksï¼Œæ— æ³•ä½¿ç”¨ SOCKS5 ä»£ç†ã€‚è¯·è¿è¡Œ: pip install pysocks[/]")
        return False, "Missing PySocks"

    proxies = {
        'http': f'socks5://127.0.0.1:{local_port}',
        'https': f'socks5://127.0.0.1:{local_port}'
    }
    try:
        start = time.time()
        resp = requests.get(domain, proxies=proxies, timeout=timeout, verify=False)
        end = time.time()
        if resp.status_code < 400:
            safe_print(f"[check] âœ… ç«¯å£{local_port} å»¶è¿Ÿ{round((end - start) * 1000)}ms") if GLOBAL_CFG.get("debug_mode") else 0
            return round((end - start) * 1000), None
        else:
            safe_print(f"[check] âŒ ç«¯å£{local_port} HTTP {resp.status_code}") if GLOBAL_CFG.get("debug_mode") else 0
            return False, f"HTTP {resp.status_code}"

    # è°ƒè¯•æ¨¡å¼è¾“å‡º
    except requests.exceptions.ConnectTimeout:
        safe_print(f"[check] âŒ ç«¯å£{local_port} è¿æ¥è¶…æ—¶") if GLOBAL_CFG.get("debug_mode") else 0
        return False, "è¿æ¥è¶…æ—¶"
    except requests.exceptions.ReadTimeout:
        safe_print(f"[check] âŒ ç«¯å£{local_port} è¯»å–è¶…æ—¶") if GLOBAL_CFG.get("debug_mode") else 0
        return False, "è¯»å–è¶…æ—¶"
    except (BadStatusLine, RemoteDisconnected):
        safe_print(f"[check] âŒ ç«¯å£{local_port} æ¡æ‰‹å¤±è´¥") if GLOBAL_CFG.get("debug_mode") else 0
        return False, "æ¡æ‰‹å¤±è´¥"
    except requests.exceptions.ConnectionError as e:
        safe_print(f"[check] âŒ ç«¯å£{local_port} è¿æ¥é”™è¯¯: {e}") if GLOBAL_CFG.get("debug_mode") else 0
        return False, f"è¿æ¥é”™è¯¯: {e}"
    except Exception as e:
        safe_print(f"[check] âŒ ç«¯å£{local_port} æœªçŸ¥å¼‚å¸¸: {e}") if GLOBAL_CFG.get("debug_mode") else 0
        return False, str(e)

# é€šè¿‡ä»£ç†æµ‹è¯•ä¸‹è½½é€Ÿåº¦
def check_speed_download(local_port, url_file, timeout=10, conn_timeout=5, max_mb=5, min_kb=1):
    """é€šè¿‡ä»£ç†æµ‹è¯•ä¸‹è½½é€Ÿåº¦"""
    targets = GLOBAL_CFG.get("speed_targets", [])

    pool = [url_file] + targets if url_file else list(targets)
    if not url_file: random.shuffle(pool)

    pool = [u for u in pool if u]
    if not pool: return 0.0

    proxies = {
        'http': f'socks5://127.0.0.1:{local_port}',
        'https': f'socks5://127.0.0.1:{local_port}'
    }

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
        "Accept": "*/*",
        "Connection": "keep-alive"
    }

    limit_bytes = max_mb * 1024 * 1024

    for target_url in pool:
        try:
            with requests.get(target_url, proxies=proxies, headers=headers, stream=True,
                              timeout=(conn_timeout, timeout), verify=False) as r:

                if r.status_code >= 400:
                    continue

                start_time = time.time()
                total_bytes = 0

                for chunk in r.iter_content(chunk_size=32768):
                    if chunk:
                        total_bytes += len(chunk)

                    curr_time = time.time()
                    if (curr_time - start_time) > timeout or total_bytes >= limit_bytes:
                        break

                duration = time.time() - start_time
                if duration <= 0.1: duration = 0.1

                if total_bytes < (min_kb * 1024):
                    if duration > (timeout * 0.8):
                        return 0.0
                    continue

                speed_bps = total_bytes / duration
                speed_mbps = speed_bps / 125000

                return round(speed_mbps, 2)

        except (requests.exceptions.ConnectTimeout, requests.exceptions.ReadTimeout,
                requests.exceptions.ConnectionError):
            continue
        except Exception:
            pass

# å¤„ç†ä¸€æ‰¹ä»£ç†çš„å®Œæ•´æ£€æŸ¥æµç¨‹
def Checker(proxyList, localPortStart, testDomain, timeOut, t2exec, t2kill,
            checkSpeed=False, speedUrl="", sortBy="ping", speedCfg=None,
            speedSemaphore=None, maxInternalThreads=50,
            progress=None, task_id=None):
    """å¤„ç†ä¸€æ‰¹ä»£ç†çš„å®Œæ•´æ£€æŸ¥æµç¨‹"""

    current_live_results = []
    if speedCfg is None: speedCfg = {}

    configPath, valid_mapping, err = create_batch_config_file(proxyList, localPortStart, TEMP_DIR)
    if err or not valid_mapping:
        return current_live_results

    proc = run_core(CORE_PATH, configPath)
    if not proc:
        safe_print(f"[bold red][æ‰¹å¤„ç†é”™è¯¯] æ— æ³•åˆ›å»ºæ ¸å¿ƒè¿›ç¨‹ï¼[/]")
        return current_live_results

    core_started = False
    start_time = time.time()
    max_wait = max(t2exec, 5.0)
    while (time.time() - start_time) < max_wait:
        poll_result = proc.poll()
        if poll_result is not None:
            exitcode = proc.returncode
            if exitcode == 0: break

            try:
                out_data, _ = proc.communicate(timeout=1)
                if out_data:
                    error_msg = out_data.strip()[-2000:]
            except Exception as e:
                error_msg = f"è¯»å–é”™è¯¯è¾“å‡ºå¤±è´¥ï¼š{e}"

            safe_print(f"[bold red]æ‰¹å¤„ç†å¤±è´¥[/] [yellow]æ ¸å¿ƒæœªå¯åŠ¨ (Exit: {exitcode})[/]")
            safe_print(f"[dim]é”™è¯¯ä¿¡æ¯ï¼š{error_msg[:300]}[/]")

            save_failed_batch(configPath, error_msg, exitcode)

            kill_core(proc)
            return current_live_results
        if is_port_in_use(valid_mapping[0][1]):
            core_started = True
            break
        time.sleep(0.1)

    if core_started:
        time.sleep(0.3)

    if not core_started:
        exitcode = proc.poll()
        error_msg = "æœªçŸ¥é”™è¯¯"
        try:
            if proc.stdout:
                err_lines = []
                for line in proc.stdout:
                    err_lines.append(line.strip())
                    if len(err_lines) > 50:
                        break
                if err_lines:
                    error_msg = "\n".join(err_lines[-20:])
        except:
            try:
                proc.wait(timeout=0.5)
                error_msg = "æ ¸å¿ƒé™é»˜å¤±è´¥"
            except:
                error_msg = "æ ¸å¿ƒè¶…æ—¶"

        safe_print(f"[bold red]æ‰¹å¤„ç†å¤±è´¥[/] [yellow]æ ¸å¿ƒæœªå¯åŠ¨ (Exit: {exitcode})[/]")
        safe_print(f"[dim]é”™è¯¯ä¿¡æ¯ï¼š{error_msg[:300]}[/]")

        save_failed_batch(configPath, error_msg, exitcode)

        exit_code = proc.poll()

        kill_core(proc)
        return current_live_results

    def check_single_port(item):
        if CTRL_C: return None
        target_url, target_port = item

        proxy_speed = 0.0

        conf = None
        try:
            if target_url.startswith("vless://"):
                conf = parse_vless(target_url)
            elif target_url.startswith("vmess://"):
                conf = parse_vmess(target_url)
            elif target_url.startswith("ss://"):
                conf = parse_ss(target_url)
            elif target_url.startswith("trojan://"):
                conf = parse_trojan(target_url)
        except:
            pass

        addr_info = f"{conf['address']}:{conf['port']}" if conf else "æœªçŸ¥"
        proxy_tag = get_proxy_tag(target_url)

        ping_res, error_reason = check_connection(target_port, testDomain, timeOut)

        if ping_res:
            if checkSpeed:
                with (speedSemaphore if speedSemaphore else Lock()):
                    proxy_speed = check_speed_download(target_port, speedUrl, **speedCfg)
                sp_color = "green" if proxy_speed > 15 else "yellow" if proxy_speed > 5 else "red"
                safe_print(
                    f"[green][å­˜æ´»][/] [white]{addr_info:<25}[/] | {ping_res:>4}ms | [{sp_color}]{proxy_speed:>5} Mbps[/] | {proxy_tag}")
            else:
                safe_print(f"[green][å­˜æ´»][/] [white]{addr_info:<25}[/] | {ping_res:>4}ms | {proxy_tag}")

            if progress and task_id is not None:
                progress.advance(task_id, 1)
            return (target_url, ping_res, proxy_speed)

        else:
            if progress and task_id is not None:
                progress.advance(task_id, 1)
            return None

    max_workers = min(len(valid_mapping), maxInternalThreads)
    with ThreadPoolExecutor(max_workers=max_workers) as inner_exec:
        raw_results = list(inner_exec.map(check_single_port, valid_mapping))

    current_live_results = [r for r in raw_results if r is not None]

    kill_core(proc)
    time.sleep(t2kill)
    try:
        if os.path.exists(configPath):
            os.remove(configPath)
    except:
        pass

    return current_live_results

# è¿è¡Œä¸»è¦æ‰§è¡Œé€»è¾‘
def run_logic(args):
    """ä¸»è¦æ‰§è¡Œé€»è¾‘"""
    global CORE_PATH, CTRL_C

    # ctrl + c åœæ­¢
    def signal_handler(sig, frame):
        global CTRL_C
        CTRL_C = True
        safe_print("[bold red]CTRL+C - æ­£åœ¨åœæ­¢...[/]")
        kill_all_cores_manual()
        sys.exit(0)

    import signal
    signal.signal(signal.SIGINT, signal_handler)

    CORE_PATH = shutil.which(args.core)
    if not CORE_PATH:
        # å¸¸è§æ ¸å¿ƒè·¯å¾„
        candidates = ["xray.exe", "xray", "v2ray.exe", "v2ray", "bin/xray.exe", "bin/xray"]
        for c in candidates:
            if os.path.exists(c):
                CORE_PATH = os.path.abspath(c)
                break

    if not CORE_PATH:
        safe_print(f"[bold red]\\n[é”™è¯¯] æœªæ‰¾åˆ°æ ¸å¿ƒ (xray/v2ray)ï¼[/]")
        safe_print(f"[dim]è¯·æ‰‹åŠ¨ä¸‹è½½ï¼šhttps://github.com/XTLS/Xray-core/releases[/]")
        return

    safe_print(f"[dim]æ£€æµ‹åˆ°æ ¸å¿ƒï¼š{CORE_PATH}[/]")

    safe_print(f"[yellow]>> æ¸…ç†æ®‹ç•™çš„æ ¸å¿ƒè¿›ç¨‹...[/]")
    killed_count = 0
    target_names = [os.path.basename(CORE_PATH).lower(), "xray.exe", "v2ray.exe", "xray", "v2ray"]
    for proc in psutil.process_iter(['pid', 'name']):
        try:
            if proc.info['name'] and proc.info['name'].lower() in target_names:
                proc.kill()
                killed_count += 1
        except:
            pass

    if killed_count > 0: safe_print(f"[green]>> å·²ç»ˆæ­¢ {killed_count} ä¸ªæ—§è¿›ç¨‹[/]")
    time.sleep(0.5)

    lines = set()
    total_found_raw = 0

    # å¦‚æœæœ‰ä¼ é€’çš„æ–‡ä»¶
    if args.file:
        fpath = args.file.strip('"')
        if os.path.exists(fpath):
            safe_print(f"[cyan]>> è¯»å–æ–‡ä»¶ï¼š{fpath}[/]")
            with open(fpath, 'r', encoding='utf-8', errors='ignore') as f:
                parsed, count = parse_content(f.read())
                total_found_raw += count
                lines.update(parsed)

    # å¦‚æœæœ‰ä¼ é€’çš„url
    if args.url:
        links = fetch_url(args.url)
        lines.update(links)

    # å¦‚æœä½¿ç”¨èšåˆå™¨
    if AGGREGATOR_AVAILABLE and getattr(args, 'agg', False):
        sources_map = GLOBAL_CFG.get("sources", {})
        cats = args.agg_cats if args.agg_cats else list(sources_map.keys())
        kws = args.agg_filter if args.agg_filter else []
        try:
            agg_links = aggregator.get_aggregated_links(sources_map, cats, kws, log_func=safe_print, console=console)
            lines.update(agg_links)
        except:
            pass

    if hasattr(args, 'direct_list') and args.direct_list:
        parsed_agg, _ = parse_content("\n".join(args.direct_list))
        lines.update(parsed_agg)

    if args.reuse and os.path.exists(args.output):
        with open(args.output, 'r', encoding='utf-8') as f:
            parsed, count = parse_content(f.read())
            lines.update(parsed)

    full = list(lines)
    if not full:
        safe_print(f"[bold red]æ²¡æœ‰å¾…æ£€æŸ¥çš„ä»£ç†ã€‚[/]")
        return

    p_per_batch = GLOBAL_CFG.get("proxies_per_batch", 50)
    needed_cores = (len(full) + p_per_batch - 1) // p_per_batch
    threads = min(args.threads, needed_cores)
    if threads < 1: threads = 1

    chunks = list(split_list(full, threads))
    ports = []
    curr_p = args.lport
    for chunk in chunks:
        ports.append(curr_p)
        curr_p += len(chunk) + 10

    results = []

    speed_config_map = {
        "timeout": GLOBAL_CFG.get("speed_download_timeout", 10),
        "conn_timeout": GLOBAL_CFG.get("speed_connect_timeout", 5),
        "max_mb": GLOBAL_CFG.get("speed_max_mb", 5),
        "min_kb": GLOBAL_CFG.get("speed_min_kb", 1)
    }
    speed_semaphore = Semaphore(GLOBAL_CFG.get("speed_check_threads", 3))

    progress_columns = [
        SpinnerColumn(style="bold yellow"),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(bar_width=40, style="dim", complete_style="green", finished_style="bold green"),
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        TimeElapsedColumn(),
        TextColumn("â€¢"),
        TimeRemainingColumn(),
    ]

    console.print(f"\n[magenta]å¯åŠ¨ {threads} ä¸ªæ ¸å¿ƒï¼ˆæ‰¹æ¬¡ï¼‰æ£€æŸ¥ {len(full)} ä¸ªä»£ç†...[/]")

    with Progress(*progress_columns, console=console, transient=False) as progress:
        task_id = progress.add_task("[cyan]æ­£åœ¨æ£€æŸ¥ä»£ç†...", total=len(full))

        with ThreadPoolExecutor(max_workers=threads) as executor:
            futures = []
            for i in range(len(chunks)):
                ft = executor.submit(
                    Checker, chunks[i], ports[i], args.domain, args.timeout,
                    args.t2exec, args.t2kill, args.speed_check, args.speed_test_url, args.sort_by,
                    speed_config_map, speed_semaphore,
                    GLOBAL_CFG.get("max_internal_threads", 50),
                    progress, task_id
                )
                futures.append(ft)

            try:
                for f in as_completed(futures):
                    chunk_result = f.result()
                    if chunk_result:
                        results.extend(chunk_result)
            except KeyboardInterrupt:
                CTRL_C = True
                executor.shutdown(wait=False)

    if args.sort_by == "speed":
        results.sort(key=lambda x: x[2], reverse=True)
    else:
        results.sort(key=lambda x: x[1])

    with open(args.output, 'a', encoding='utf-8') as f:
        for r in results:
            f.write(r[0] + '\n')

    if results:
        table = Table(title=f"ç»“æœï¼ˆå‰15ä¸ªï¼Œå…±{len(results)}ï¼‰", box=box.ROUNDED)
        table.add_column("å»¶è¿Ÿ", justify="right", style="green")
        if args.speed_check:
            table.add_column("é€Ÿåº¦ (Mbps)", justify="right", style="bold cyan")
        table.add_column("æ ‡ç­¾/åè®®", justify="left", overflow="fold")

        for r in results[:15]:
            tag_display = get_proxy_tag(r[0])
            if len(tag_display) > 50: tag_display = tag_display[:47] + "..."
            if args.speed_check:
                table.add_row(f"{r[1]} ms", f"{r[2]}", tag_display)
            else:
                table.add_row(f"{r[1]} ms", tag_display)
        console.print(table)

    safe_print(f"\n[bold green]å®Œæˆï¼æœ‰æ•ˆä»£ç†æ•°ï¼š{len(results)}ã€‚ç»“æœå·²ä¿å­˜è‡³ï¼š{args.output}[/]")

# æ‰‹åŠ¨æ€æ­»æ‰€æœ‰æ ¸å¿ƒè¿›ç¨‹
def kill_all_cores_manual():
    """æ‰‹åŠ¨æ€æ­»æ‰€æœ‰æ ¸å¿ƒè¿›ç¨‹"""
    killed_count = 0
    target_names = ["xray.exe", "v2ray.exe", "xray", "v2ray"]

    safe_print("[yellow]>> å¼ºåˆ¶é‡ç½®æ‰€æœ‰æ ¸å¿ƒ...[/]")

    for proc in psutil.process_iter(['pid', 'name']):
        try:
            if proc.info['name'] and any(name in proc.info['name'].lower() for name in target_names):
                proc.kill()
                killed_count += 1
                safe_print(f"[green]âœ“ å·²ç»ˆæ­¢ PID {proc.info['pid']}[/]")
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            continue

    if OS_SYSTEM == "windows":
        try:
            result = subprocess.run(
                ["taskkill", "/F", "/IM", "xray.exe", "/T"],
                capture_output=True, text=True, timeout=5
            )
            if result.returncode == 0:
                killed_count += result.stdout.count("SUCCESS")
        except:
            pass

    for port in range(10000, 11000):
        if is_port_in_use(port):
            try:
                with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                    s.settimeout(0.1)
                    s.connect(('127.0.0.1', port))
            except:
                pass

    time.sleep(1.0)
    remaining = 0
    for proc in psutil.process_iter(['name']):
        try:
            if proc.info['name'] and any(name in proc.info['name'].lower() for name in target_names):
                remaining += 1
        except:
            pass

    safe_print(f"[bold green]âœ“ é‡ç½®å®Œæˆï¼šå·²ç»ˆæ­¢ {killed_count} ä¸ªæ ¸å¿ƒ[/]")
    if remaining > 0:
        safe_print(f"[yellow]âš  å‰©ä½™ {remaining} ä¸ªè¿›ç¨‹ï¼ˆ3ç§’åè‡ªåŠ¨é‡è¯•ï¼‰[/]")
        time.sleep(3)
        kill_all_cores_manual()
    else:
        safe_print("[bold green]âœ… å…¨éƒ¨æ¸…ç†å®Œæ¯•ï¼[/]")

# äº¤äº’å¼ä¸»èœå•
def interactive_menu():
    """äº¤äº’å¼èœå•"""
    while True:

        table = Table(show_header=True, header_style="bold magenta", box=box.ROUNDED, expand=True)
        table.add_column("åºå·", style="cyan", width=4, justify="center")
        table.add_column("æ“ä½œ", style="white")
        table.add_column("æè¿°", style="dim")

        table.add_row("1", "æ–‡ä»¶", "ä».txtæ–‡ä»¶åŠ è½½ä»£ç†")
        table.add_row("2", "é“¾æ¥", "ä»URLåŠ è½½ä»£ç†")
        table.add_row("3", "é‡æ–°æ£€æŸ¥", f"é‡æ–°æ£€æŸ¥ {GLOBAL_CFG['output_file']}")

        if AGGREGATOR_AVAILABLE:
            table.add_row("4", "èšåˆå™¨", "ä»urlé›†åˆæ‰¹é‡ä¸‹è½½æ•°æ®ã€åˆå¹¶å¹¶æ£€æŸ¥")

        table.add_row("5", "é‡ç½®æ ¸å¿ƒ", "æ€æ­»æ‰€æœ‰xrayè¿›ç¨‹")
        table.add_row("0", "é€€å‡º", "å…³é—­ç¨‹åº")

        console.print(table)

        valid_choices = ["0", "1", "2", "3", "4", "5", "6"] if AGGREGATOR_AVAILABLE else ["0", "1", "2", "3", "5", "6"]
        ch = Prompt.ask("[bold yellow]>[/] è¯·é€‰æ‹©æ“ä½œ", choices=valid_choices)

        # é€€å‡º
        if ch == '0':
            sys.exit()

        # é€‰é¡¹ä¼ é€’(é»˜è®¤)
        defaults = {
            "file": None, "url": None, "reuse": False,
            "domain": GLOBAL_CFG['test_domain'],
            "timeout": GLOBAL_CFG['timeout'],
            "lport": GLOBAL_CFG['local_port_start'],
            "threads": GLOBAL_CFG['threads'],
            "core": GLOBAL_CFG['core_path'],
            "t2exec": GLOBAL_CFG['core_startup_timeout'],
            "t2kill": GLOBAL_CFG['core_kill_delay'],
            "output": GLOBAL_CFG['output_file'],
            "shuffle": GLOBAL_CFG['shuffle'],
            "number": None,
            "direct_list": None,
            "speed_check": GLOBAL_CFG['check_speed'],
            "speed_test_url": GLOBAL_CFG['speed_test_url'],
            "sort_by": GLOBAL_CFG['sort_by'],
            "menu": True
        }

        # æ–‡ä»¶åŠ è½½
        if ch == '1':
            defaults["file"] = Prompt.ask("[cyan][?][/] æ–‡ä»¶è·¯å¾„").strip('"')
            if not defaults["file"]: continue

        # ç½‘å€åŠ è½½
        elif ch == '2':
            defaults["url"] = Prompt.ask("[cyan][?][/] URLé“¾æ¥").strip()
            if not defaults["url"]: continue

        # é‡æ–°æ£€æŸ¥
        elif ch == '3':
            defaults["reuse"] = True

        # èšåˆå™¨ = æ”¶é›† + æ¸…æ´— + åœ°ç†æ ‡è®°
        elif ch == '4' and AGGREGATOR_AVAILABLE:
            console.print(
                Panel(f"å¯ç”¨ç±»åˆ«ï¼š[green]{', '.join(GLOBAL_CFG.get('sources', {}).keys())}[/]", title="èšåˆå™¨"))
            cats = Prompt.ask("è¯·è¾“å…¥ç±»åˆ«ï¼ˆç©ºæ ¼åˆ†éš”ï¼‰", default="1 2").split()
            kws = Prompt.ask("è¿‡æ»¤å…³é”®è¯ï¼ˆç©ºæ ¼åˆ†éš”ï¼‰", default="").split()

            sources_map = GLOBAL_CFG.get("sources", {})
            try:
                raw_links = aggregator.get_aggregated_links(sources_map, cats, kws, console=console)
                if not raw_links:
                    safe_print("[bold red]èšåˆå™¨æœªæ‰¾åˆ°ä»»ä½•å†…å®¹ã€‚[/]")
                    time.sleep(2)
                    continue
                defaults["direct_list"] = raw_links
            except Exception as e:
                safe_print(f"[bold red]èšåˆå™¨é”™è¯¯ï¼š{e}[/]")
                continue
        # èšåˆå™¨æ”¶é›†æ¸…æ´—å®Œåå°†ä¼šæ‰§è¡Œæ£€æŸ¥æ˜¯å¦å¯ç”¨

        elif ch == '5':
            kill_all_cores_manual()
            continue

        if Confirm.ask("æ˜¯å¦å¯ç”¨é€Ÿåº¦æµ‹è¯•ï¼Ÿ", default=False):
            defaults["speed_check"] = True
            defaults["sort_by"] = "speed"
        else:
            defaults["speed_check"] = False
            defaults["sort_by"] = "ping"

        args = SimpleNamespace(**defaults)

        safe_print("\n[yellow]>>> æ­£åœ¨åˆå§‹åŒ–æ£€æŸ¥...[/]")
        time.sleep(0.5)

        try:
            run_logic(args)
        except Exception as e:
            safe_print(f"[bold red]ä¸¥é‡é”™è¯¯ï¼š{e}[/]")
            # tracebackå¤„ç†å’Œè°ƒè¯•ç¨‹åºä¸­çš„å¼‚å¸¸ã€‚å®ƒå¯ä»¥æå–ã€æ ¼å¼åŒ–å¹¶æ‰“å°å¼‚å¸¸çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬é”™è¯¯å‘ç”Ÿçš„ä½ç½®å’Œè°ƒç”¨æ ˆä¿¡æ¯ï¼Œä»è€Œå¸®åŠ©å¼€å‘è€…å¿«é€Ÿå®šä½é—®é¢˜ã€‚
            import traceback
            error_data = traceback.format_exc()
            MAIN_LOGGER.log(f"å´©æºƒæŠ¥å‘Šï¼š\n{error_data}")

            traceback.print_exc()

        Prompt.ask("\n[bold]æŒ‰Enterè¿”å›èœå•...[/]", password=False)

# ä¸»å…¥å£
def main():
    """ä¸»å…¥å£"""
    parser = argparse.ArgumentParser(description="å‘½ä»¤è¡Œå‚æ•°ä¼ é€’")
    parser.add_argument("-m", "--menu", action="store_true")
    parser.add_argument("-f", "--file")
    parser.add_argument("-u", "--url")
    parser.add_argument("--reuse", action="store_true")

    parser.add_argument("-t", "--timeout", type=int, default=GLOBAL_CFG['timeout'])
    parser.add_argument("-l", "--lport", type=int, default=GLOBAL_CFG['local_port_start'])
    parser.add_argument("-T", "--threads", type=int, default=GLOBAL_CFG['threads'])
    parser.add_argument("-c", "--core", default=GLOBAL_CFG['core_path'])
    parser.add_argument("--t2exec", type=float, default=GLOBAL_CFG['core_startup_timeout'])
    parser.add_argument("--t2kill", type=float, default=GLOBAL_CFG['core_kill_delay'])
    parser.add_argument("-o", "--output", default=GLOBAL_CFG['output_file'])
    parser.add_argument("-d", "--domain", default=GLOBAL_CFG['test_domain'])
    parser.add_argument("-s", "--shuffle", action='store_true', default=GLOBAL_CFG['shuffle'])
    parser.add_argument("-n", "--number", type=int)
    parser.add_argument("--agg", action="store_true", help="å¯åŠ¨èšåˆå™¨")
    parser.add_argument("--agg-cats", nargs='+', help="èšåˆå™¨ç±»åˆ«ï¼ˆå¦‚ï¼š1 2ï¼‰")
    parser.add_argument("--agg-filter", nargs='+', help="è¿‡æ»¤å…³é”®è¯ï¼ˆå¦‚ï¼švless realityï¼‰")
    parser.add_argument("--speed", action="store_true", dest="speed_check", help="å¯ç”¨é€Ÿåº¦æµ‹è¯•")
    parser.add_argument("--sort", choices=["ping", "speed"], default=GLOBAL_CFG['sort_by'], dest="sort_by",help="æ’åºæ–¹å¼")
    parser.add_argument("--speed-url", default=GLOBAL_CFG['speed_test_url'], dest="speed_test_url")
    parser.add_argument("--self-test", action="store_true", help="è¿è¡ŒURLè§£æè‡ªæµ‹")
    parser.add_argument("--debug", action="store_true", help="Debugæ¨¡å¼ï¼ˆproxies_per_batch=1, threads=1ï¼‰")

    # åˆ—è¡¨çš„ç¬¬ä¸€ä¸ªå…ƒç´  sys.argv[0] æ°¸è¿œæ˜¯è„šæœ¬æ–‡ä»¶åï¼Œå…¶ä½™å…ƒç´ æ˜¯ç”¨æˆ·ä¼ å…¥çš„å‚æ•°ã€‚
    # å½“æ²¡æœ‰å…¶ä»–å‚æ•°ä¼ é€’,åªæœ‰ä¸€ä¸ªæ–‡ä»¶å
    if len(sys.argv) == 1:
        # è¿›å…¥ä¸»èœå•
        interactive_menu()

    # æœ‰å‚æ•°ä¼ é€’
    else:
        # è·å–ä¼ é€’çš„å‚æ•°
        args = parser.parse_args()

        # getattr æ˜¯ä¸€ä¸ªå†…ç½®å‡½æ•°ï¼Œç”¨äºåŠ¨æ€è·å–å¯¹è±¡çš„å±æ€§å€¼ã€‚å®ƒæä¾›äº†ä¸€ç§çµæ´»çš„æ–¹å¼æ¥è®¿é—®å¯¹è±¡çš„å±æ€§ï¼Œå°¤å…¶æ˜¯åœ¨å±æ€§åä¸ç¡®å®šæˆ–éœ€è¦åŠ¨æ€å†³å®šçš„æƒ…å†µä¸‹ã€‚
        # æŸ¥æ‰¾ä¼ å…¥çš„å‚æ•°åˆæ²¡æœ‰self_test,æœ‰åˆ™è§¦å‘URLè§£æè‡ªæµ‹
        # è¿è¡Œæ–¹å¼ï¼špython v2rayChecker.py --self-test
        if getattr(args, 'self_test', False):
            print("æ­£åœ¨è¿è¡ŒURLè§£æè‡ªæµ‹...")
            success = _self_test_clean_url()
            sys.exit(0 if success else 1)

        # è°ƒè¯•æ¨¡å¼
        if getattr(args, 'debug', False):
            GLOBAL_CFG['debug_mode'] = True
            GLOBAL_CFG['proxies_per_batch'] = 1
            GLOBAL_CFG['threads'] = 1
            safe_print(f"[yellow][è°ƒè¯•æ¨¡å¼] proxies_per_batch=1, threads=1[/]")

        # å½“æœ‰-mæ—¶å¯åŠ¨ä¸»èœå•
        if args.menu:
            interactive_menu()

        # åªè¦åœ¨æ‰§è¡Œè„šæœ¬æ—¶ä¼ é€’äº†è‡³å°‘ä¸€ä¸ªæœ‰æ•ˆå‚æ•°ï¼Œå¹¶ä¸”è¿™äº›å‚æ•°ä¸åŒ…å« --menu æˆ– --self-testï¼Œå°±è°ƒç”¨ run_logic(args) æ‰§è¡Œæ­£å¸¸ä»»åŠ¡ã€‚
        else:
            # æ­£å¸¸ä»»åŠ¡æ‰§è¡Œ,è·³è¿‡äº¤äº’ç»ˆç«¯,ç›´æ¥é€šè¿‡å‚æ•°æ‰§è¡Œ
            run_logic(args)


if __name__ == '__main__':
    try:
        # ä¸»ç¨‹åºå…¥å£
        main()
    except KeyboardInterrupt:
        print(f"\n{Fore.RED}é€€å‡ºã€‚{Style.RESET_ALL}")
    finally:
        try:
            # é€’å½’åˆ é™¤ä¸´æ—¶ç›®å½•
            shutil.rmtree(TEMP_DIR)
        except:
            pass